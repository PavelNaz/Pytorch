{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "-6aLop3u7o3j"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTuEwDjX8fdU",
    "outputId": "9fc71ec7-24ce-4f99-e46a-d35508a96818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.CIFAR100(root='data/', train=True, download=True)\n",
    "\n",
    "\n",
    "class MyOwnCifar(torch.utils.data.Dataset):\n",
    "   \n",
    "    def __init__(self, init_dataset, transform=None):\n",
    "        self._base_dataset = init_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self._base_dataset[idx][0]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, self._base_dataset[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sTadwNjA8fyJ"
   },
   "outputs": [],
   "source": [
    "trans_actions = transforms.Compose([transforms.Resize(44),\n",
    "                                    transforms.RandomCrop(32, padding=4), \n",
    "                                    transforms.ToTensor()])\n",
    "\n",
    "\n",
    "def train_valid_split(Xt):\n",
    "    X_train, X_test = train_test_split(Xt, test_size=0.2, random_state=13)\n",
    "    return X_train, X_test\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, trans_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DFhyFTPD8f1D"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                          batch_size=128,\n",
    "                          shuffle=False,\n",
    "                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "hEZAkqfp8f4L",
    "outputId": "5bbd6c29-9166-48c4-d4bf-65e546dc2eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 3, 32, 32])\n",
      "tensor(93)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAaxklEQVR4nO2dbYxcZ3XH/+e+zMvOrtd2nBgTp3UIQZAiCHRlUYEQBYFShBSQqpR8QJEaYVQRqUj0Q5RKJZWqCqoC4hOVaSJClZKkvIioQi1phBTxJcRJg/PiAknkJF7Wu05sx+t9mblz7+mHuWk30XPOrnd3Zpw8/5+02pl75rn3zHPnzJ15/nPOEVUFIeTNTzJuBwgho4HBTkgkMNgJiQQGOyGRwGAnJBIY7IREQraVwSJyHYBvAUgB/LOqfnWdx1PnI2TIqKqEtstmdXYRSQH8BsDHAZwA8AiAG1X1aWcMg52QIWMF+1Y+xh8E8IyqPqeqPQD3ALh+C/sjhAyRrQT75QBeXHP/RL2NEHIRsqXv7BtBRA4BODTs4xBCfLYS7LMArlhzf3+97TWo6mEAhwF+ZydknGzlY/wjAK4WkStFpAHgswDu3x63CCHbzaav7KraF5FbAPwnBtLbnar61LZ5RgjZVjYtvW3qYPwYT8jQGYb0Rgh5A8FgJyQSGOyERAKDnZBIYLATEgkMdkIigcFOSCQw2AmJBAY7IZHAYCckEhjshETC0PPZ13LNu96Ge+/++6Ct6K+a44re+eD2VsN+r0olNW2J5vY4tC94n1r2zTH9omfvL3P8SJxTo/bzNn4WjTS3x1QoTVu/sm3O00aahucqsU8LKnRN29Liy7YfPfu1Yx2u2bTnPkkr0+bNVdc510tLS6atrMLnutmeNMdMTu4Ibv+zP7fLQPLKTkgkMNgJiQQGOyGRwGAnJBIY7IREAoOdkEgYqfRWVX0snj8TtBW9whyXGW9JSaNpjknFfmqOmoSV1RXT1jSOl8CutqVOJa6ysiUeTxrKs4ZpK4rwPovSlrUqtTU0r45YIva1oijC51ML+1iS2rZGbp/PNLPlUqnC+yz69uttcWnRtBXeXIVVzwGJbWw0WsHtrWZ4OwBkhmwrsI/DKzshkcBgJyQSGOyERAKDnZBIYLATEgkMdkIiYUvSm4gcB7AIoATQV9UZ7/FVVWG1G87+UVsJQXtiKrg9Sx1pwsl661X2wVYc2QWGVJY3nOw1I/trgP1eK6nzPpxceAZbz5DCBjhapCMZwVYO0euGpb4Kth+5rSii7UhvDUcC7HfDUtm55XAmJQCcPheWhwGgL/aTbrTs12NnMvwaBoA8D4+ztgNAmoYnS8Q+X9uhs/+xqr60DfshhAwRfownJBK2GuwK4Gci8qiIHNoOhwghw2GrH+M/pKqzInIZgAdE5H9U9aG1D6jfBA4BwN7Ldm3xcISQzbKlK7uqztb/FwD8GMDBwGMOq+qMqs5MT3e2cjhCyBbYdLCLSEdEpl69DeATAJ7cLscIIdvLVj7G7wXw43qpPwPwr6r6H+4IAZIknEfV6tjF9aanwh//G5njfmlLJD0jEwqwJaN6p8GtSWr73pqwbYlTfbFwqjmurNqFDXuG1FT07eflqYOJI/OVfWeOe+HjJamdR5c4mYqJI0Vq356r1dVwMcqzZ8+aYxad4pBJy5ZZswl7IrOW/alWEN5npfZ8iBm6Q5DeVPU5AO/d7HhCyGih9EZIJDDYCYkEBjshkcBgJyQSGOyERMJIC04mImjl4aKNU440kRnyT2J28oKnQKDpZKldumfatFlyWOlIeeeW7Owq9bLGnAKc3rg8C2dKpakzIV5imydh9uznnefhOW617blvd2wbSrsQqJcFmBuZaNO7LzXHrHpFG5t2al6ns9u0tZq2BLvySlhKLcXuYZclYT9UHWnTtBBC3lQw2AmJBAY7IZHAYCckEhjshETCSFfj0yTFdGdH0DbRnLAHavg9ySkHBjchwKmr1hd7hXlpKZw8sbhiJ6YUlX0sr42T1d4HAJoNu91Rw0gYsWrTAUDptGQqndp1RWGv/E5OhVefm06dtkbDVlc8P0q1n5sYddwmJu1jTaza85E07HM20Qi/tgGgkdpq07LRj2zZScrqrobr5PX79lzwyk5IJDDYCYkEBjshkcBgJyQSGOyERAKDnZBIGLn0tmMinGiSOfXkCkN26fdtOaZf2HLY6rLd4unM6VnTNv/y6eD28yu2VKNOi6qpKVuq2TFlJ+SIk/hhiWGV0boKACqnhlvp2CpHVrRq1yVOqyatbClPnXGlc80qjbp2ifN6azbtVk2ZkcgFAM3MSeZSp1VZEk54WSls6W2pG06wKktKb4RED4OdkEhgsBMSCQx2QiKBwU5IJDDYCYmEdaU3EbkTwKcALKjqu+ttuwHcC+AAgOMAblDVcBrOGhJJ0G5Y2W22NKRJWGJbLewaXadOLZi22RPHTduLL/7atPUMqak9eYk55pLLdpq2CaflVd6wJZ7CkVd6RuuiRmZnebWatizUatoZdr2uLX1aUt+qk8nllLtDqU72ndOGql+G5TynbCASo74bADSNLDoAaDoya1La19VWIzyucvqg5o3wfKROL6+NXNm/C+C61227FcCDqno1gAfr+4SQi5h1g73ut/76X5NcD+Cu+vZdAD69zX4RQraZzX5n36uqc/Xtkxh0dCWEXMRseYFOB4Wqzd85isghETkiIkdeOv3KVg9HCNkkmw32eRHZBwD1f3M1TFUPq+qMqs7s2W3/3psQMlw2G+z3A7ipvn0TgJ9sjzuEkGGxEent+wA+AmCPiJwA8BUAXwVwn4jcDOB5ADds5GBVpVhdDksv/dKWZM4vhVW92d+dMMfMnfydaTt16qRpW1yx5bxWO5yl1mzbWVKdjv1pptW0tZXS0aH6fXuuxMgOS8SW8kRsuabpSG+Npp2lVhnaVulk35U9p3Ck06IqTezinNawnpMVqYZcBwCVI/N52mHWsEOtYbQjq+xvx0gyowirkx24brCr6o2G6WPrjSWEXDzwF3SERAKDnZBIYLATEgkMdkIigcFOSCSMtOBkVVVYMaStxcVwMUcAODn/QnD7C7PPm2NOn3nJtC2vrpg2SR2JpB3OUmtP2NJbw+nLBkfy8vBkKDGMqk5/O1vxQt+RmlInkw6GBOQVsOyXdmZbntvH8vripcbTLmAfy5pDAFAn47B05DzJHR+N/ny5IckBQGLMfeL0MeSVnZBIYLATEgkMdkIigcFOSCQw2AmJBAY7IZEwculteTlcEPHkvJ2J9txzzwa3L7xsjylKWwZJG3ZBwVbbzkTrdMJZb62WPcbLQioKW4bKHakmyy/8PTpNbOmq72hvS31bpvTksDQLS0BeLzJvPix5CgDEzG2zZcrU6ZeXO0Ub4WTt9bp2xqSV2QYAVss87zlnxuvD6wPIKzshkcBgJyQSGOyERAKDnZBIYLATEgkjXY3v9wu8/FJ4BX3OqSf3yrlwCWpvZderq5Zldj02a8UdACaMhJfEWQFdXbVXaJtN2w9vn1lmnzZrFT93xlSFPY99Z4W8KLw6eUbbJbX3N6hKHsY7192erbxkxsq6t9LttVDq9+1jdZ3WVk4eEhJDHfJUo8xRV8zjXPAIQsgbEgY7IZHAYCckEhjshEQCg52QSGCwExIJG2n/dCeATwFYUNV319tuB/B5AKfqh92mqj9db1+9XhcvPH88aJt3EmEs+UqceluZk3jQdpJddkztMm3NRsuw2H4UhV3rzJPXPBlqMyROXTVHFXJrmjnNe832SqlVFA5Aq2XNL1BVjvTmSF6F8bxzR7qqnGQXz6ZeaytHOrSScrxaeH2jlp/3utnIlf27AK4LbP+mql5b/60b6ISQ8bJusKvqQwDs0q+EkDcEW/nOfouIHBWRO0XE/uxLCLko2GywfxvAVQCuBTAH4OvWA0XkkIgcEZEji0v2T0cJIcNlU8GuqvOqWqpqBeA7AA46jz2sqjOqOjPVsRdgCCHDZVPBLiL71tz9DIAnt8cdQsiw2Ij09n0AHwGwR0ROAPgKgI+IyLUYaC/HAXxhIwcrih5+N/di0GZltgEAkrCckDedVk25nVHWdmrGtY0WTwCQJJac58lTNp6MY0krm8XzsJnZ2VWp0w6rV9iSlyU1ea2avDptTmcl9Hq2vGlKXk4WoCeXevKaK286NitTMfF89Hp2Gawb7Kp6Y2DzHRd8JELIWOEv6AiJBAY7IZHAYCckEhjshEQCg52QSBhpwcmyLHH2bPhn9v3Saf1jtRlS2/00teWkPLd/3JOILf+oUTUwcTKomo486LHZjDhLNvKkt0bqtJpy5J/uov2LSKv9k1fM0cMb59kKQ8L0CoEWTgFL7+qYOrKidz7zPPxaTZwWYBDjPDsSH6/shEQCg52QSGCwExIJDHZCIoHBTkgkMNgJiYSRSm9QhVZhKaThyAytTjs8pmVntrVa4TEAkDlSU6/nFAY0pBVH7YA4otdEZ8I+liMnecULV1ZWgtsrJ3ttswUWfckxLCfl+eb8gNhyo5U1Vu80uHnZy2xTzw/7+uj5v7S0ZNryifDroONkAXYmw5mbVvFKgFd2QqKBwU5IJDDYCYkEBjshkcBgJyQSRroaLyJoGj/6bxgrkgDQMmzeanyz6VSydVZUV7v2Km1Dw6ujqVmbDhDn/TRzVtyt1WwAqJzV4krDK/W5l0iSOT5mm/MRho9+bT37WOKsxsNrlWVIJeK8Bjyb0/EKlaE0DWz2OesZSTntjl0r0YojJsIQQhjshMQCg52QSGCwExIJDHZCIoHBTkgkbKT90xUAvgdgLwbCw2FV/ZaI7AZwL4ADGLSAukFVz3j7SpIE7VZYRmt1pm0nDYmt2bKln8SpB+blWxR9W3pLEJa1nFJ4SMU2ekkyaWrbssTepyIsOWppP+k0td/zG1b9v4HVtCwvhxM/SkfahCFtAkDizIcnvVmSV+Jc5ypHAoTa8po6NhGn1VcvLL2VXafnVeVogAYbubL3AXxZVa8B8AEAXxSRawDcCuBBVb0awIP1fULIRcq6wa6qc6r6WH17EcAxAJcDuB7AXfXD7gLw6WE5SQjZOhf0nV1EDgB4H4CHAexV1bnadBKDj/mEkIuUDQe7iEwC+CGAL6nqubU2HRQyD36JEJFDInJERI4srTjf1wghQ2VDwS4iOQaBfreq/qjePC8i+2r7PgALobGqelhVZ1R1ptN2KooQQobKusEug1/W3wHgmKp+Y43pfgA31bdvAvCT7XePELJdbCTr7YMAPgfgCRF5vN52G4CvArhPRG4G8DyAG9bbkSQJWq1wJk+7tcMclzTCbuYNWyJRR9Yq+puruWYlmyWwP7E0Uzv7LvNaPDkZVN5bdLMVnpPuir2/xJGF8tw+WOo8t143XAtvddWWk7rO3DeaXlsuuyZfWYRtVWlLV4l658Uep7Dn2CknBzXq4RVei6rlsM3zb91gV9VfwG4V9rH1xhNCLg74CzpCIoHBTkgkMNgJiQQGOyGRwGAnJBJGW3BSBVKFF/Zzp5WQlTmWqpMJ5chaXpZXLk4bKqN1UdPJDMtz28d2057+zK6lCU1seaUwWkN5WXReMceq9DK5nMw8o8Bl4owpnJZMzukEHOmtslplOUljSWL76Em6npzX7dnPLTNOdtmz577ohSVMr3UVr+yERAKDnZBIYLATEgkMdkIigcFOSCQw2AmJhJFKb1VVYuV8uBBhq2n3essmwplypSN1wJHXktTWtSac9KTJTtvYbmd/tZ0c/s6E7UfWciQesaWmVaNIYeIVt3RsXvadV/PQUtgcVcs9lqMAQuBUEDWc9OQ1cZ6YOLUoE68QqCMTJ5bs7MyV2e/PkxRtEyHkzQSDnZBIYLATEgkMdkIigcFOSCSMdDW+7Jd45czLQVvirFbml4bfkwpnidYpM+e2htq5015undgdtk117FX1dsdukdRu29Oft2xbabShAuwaZImTIOEs7kOdunBF32mFVIV3mjjLxV6jKRj7A4DESeQRY9VdHD/MlW4AqbOKn2W2KtNo2q+Rfj/8+k5yp+7eBW4HeGUnJBoY7IREAoOdkEhgsBMSCQx2QiKBwU5IJKwrvYnIFQC+h0FLZgVwWFW/JSK3A/g8gFP1Q29T1Z96+6qqEkuL54K2YtWu0XXJrt3B7atLXXPM7Ml50/by6VdM29S03YbqDw+GJZm2kwizYzqcPAMA3a7d3keNunuAL690V8Nz0u85LZ6cY3lJMrDquwEQQ7JLjdp0ANB05ClPXnN2icSQKfuObFiVTi08pzjgxGQ4YQsApqZ2mrZlozVX30n06hmyszqvjo3o7H0AX1bVx0RkCsCjIvJAbfumqv7jBvZBCBkzG+n1Ngdgrr69KCLHAFw+bMcIIdvLBX1nF5EDAN4H4OF60y0iclRE7hSRXdvsGyFkG9lwsIvIJIAfAviSqp4D8G0AVwG4FoMr/9eNcYdE5IiIHFnpOb/LJIQMlQ0Fu4jkGAT63ar6IwBQ1XlVLXVQlf47AA6GxqrqYVWdUdWZttNPnRAyXNYNdhm0/bgDwDFV/caa7fvWPOwzAJ7cfvcIIdvFRlbjPwjgcwCeEJHH6223AbhRRK7FQAk6DuAL6+2o0chx4MBbg7bl8+HaaQDQaoazf8SRjBq5nW1W9GzJ7pWzZ0zbr48dC24vndpp79CrTduOXbZUU5b2c/Nqv/W64a9KpZMGWDntk1JP6HNUOcvkdKFC4hgTp/9T5rTDUuO5lU6qX5I6Ml9u+yGpk6noTGPeCMt5mVcb0Mrm81py2S7UO1X9BcLnztXUCSEXF/wFHSGRwGAnJBIY7IREAoOdkEhgsBMSCSMtONlsNnDV268I2k6dPGuOs9SEvlNwMnXaP03tmDRtk1O2bWU53LrqhedfMMd4ctLvXbnftE3vmjZtWdPOskslLDlWamdylX1biqwcWTHL7B9JWS2NnNMCp84jEkdSgiMdqpGZ57WaSjNHAnTOZ6m2vrbiZHU2GuEwzJxWZGkWHuNJlLyyExIJDHZCIoHBTkgkMNgJiQQGOyGRwGAnJBJGKr01Ghn2798TtDnqCU4tLAa3H3/BLiq56hTKeMtbLjNtf/Ced5m22bnw8ebnw/3rAOCpJ542bV6vune88x2mbe/kJaYtTcOy3ArCsiEA9Jw+amVpZyO6UpmpsdnSVbVJec3zsW/Iiv3KlhubDVva9FwsCvt8rpR2cdEJI3uz07QzN/NG2OZlvfHKTkgkMNgJiQQGOyGRwGAnJBIY7IREAoOdkEgYqfSWpAk6O8KyRprZOs7JkyeC22dP2NLbRMfu2fbW/W8xbTt22VlvpSH/iJPttLBgF7B89rfPmrZOZ8q0TU9fatouuTTcU0wdeU1gZ2T1YJ8XrRzJy5DDxClgqY6WZ/WOA9bJ2jP6tnkZe3nuZBXmdu++vtpSmVa2JNYtwj6mPVuuy4xMOXVei7yyExIJDHZCIoHBTkgkMNgJiQQGOyGRsO5qvIi0ADwEoFk//geq+hURuRLAPQAuAfAogM+pqr08CwACaBZ+f7FWbwHg3Nlwoklvddkcs2M6vCoNAJ2OvdrqlP1Cux1eUd21016h1dJeRT5hJNYAwNnT9ir+wrw9zsozSYx2QQCQiP2enzfDrYkAoN+zEz+gxgq52mPE62vlrMYncJQGo2ZcktrPK01sW+LYcrFfV14GjUp4NV4d5cJq2eXM4Iau7F0AH1XV92LQnvk6EfkAgK8B+Kaqvh3AGQA3b2BfhJAxsW6w64Dz9d28/lMAHwXwg3r7XQA+PRQPCSHbwkb7s6d1B9cFAA8AeBbAWdX/+0x2AsDlw3GRELIdbCjYVbVU1WsB7AdwEMA7N3oAETkkIkdE5Mjps/Z3bELIcLmg1XhVPQvg5wD+CMBO+f8G6fsBzBpjDqvqjKrO7N45sSVnCSGbZ91gF5FLRWRnfbsN4OMAjmEQ9H9aP+wmAD8ZlpOEkK2zkUSYfQDuEpEUgzeH+1T130XkaQD3iMjfAfhvAHest6NKgW4ZFgcKJwmiW4RlHEcxQrNpJzq0GvZAgZ1UkadheXDHlJNUkdqJNadPnzZtZc/249yZl0wbDPXTqlkGAJMd28dWy9YiE3GK0Fk14zzpzRGOvNpvSe7opUYbKogzRp2wUKe9knUsAE1nHvuWPOsktfStenfOmHWDXVWPAnhfYPtzGHx/J4S8AeAv6AiJBAY7IZHAYCckEhjshEQCg52QSBCvZtW2H0zkFIDn67t7ADga0sigH6+FfryWN5ofv6+qwSKFIw321xxY5Iiqzozl4PSDfkToBz/GExIJDHZCImGcwX54jMdeC/14LfTjtbxp/Bjbd3ZCyGjhx3hCImEswS4i14nIr0XkGRG5dRw+1H4cF5EnRORxETkywuPeKSILIvLkmm27ReQBEflt/X/XmPy4XURm6zl5XEQ+OQI/rhCRn4vI0yLylIj8Zb19pHPi+DHSORGRloj8UkR+Vfvxt/X2K0Xk4Tpu7hURO5UxhKqO9A9AikFZq7cBaAD4FYBrRu1H7ctxAHvGcNwPA3g/gCfXbPsHALfWt28F8LUx+XE7gL8a8XzsA/D++vYUgN8AuGbUc+L4MdI5waBG8GR9OwfwMIAPALgPwGfr7f8E4C8uZL/juLIfBPCMqj6ng9LT9wC4fgx+jA1VfQjA65PZr8egcCcwogKehh8jR1XnVPWx+vYiBsVRLseI58TxY6TogG0v8jqOYL8cwItr7o+zWKUC+JmIPCoih8bkw6vsVdW5+vZJAHvH6MstInK0/pg/9K8TaxGRAxjUT3gYY5yT1/kBjHhOhlHkNfYFug+p6vsB/AmAL4rIh8ftEDB4Z4df73+YfBvAVRj0CJgD8PVRHVhEJgH8EMCXVPXcWtso5yTgx8jnRLdQ5NViHME+C+CKNffNYpXDRlVn6/8LAH6M8VbemReRfQBQ/18YhxOqOl+/0CoA38GI5kREcgwC7G5V/VG9eeRzEvJjXHNSH/uCi7xajCPYHwFwdb2y2ADwWQD3j9oJEemIyNSrtwF8AsCT/qihcj8GhTuBMRbwfDW4aj6DEcyJiAgGNQyPqeo31phGOieWH6Oek6EVeR3VCuPrVhs/icFK57MA/npMPrwNAyXgVwCeGqUfAL6PwcfBAoPvXjdj0DPvQQC/BfBfAHaPyY9/AfAEgKMYBNu+EfjxIQw+oh8F8Hj998lRz4njx0jnBMB7MCjiehSDN5a/WfOa/SWAZwD8G4DmheyXv6AjJBJiX6AjJBoY7IREAoOdkEhgsBMSCQx2QiKBwU5IJDDYCYkEBjshkfC/Vhfn+aMxEyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for img, lbl in train_loader:\n",
    "    print(img.shape)\n",
    "    print(lbl[0])\n",
    "    plt.imshow(img[0].permute(1, 2, 0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nwNvg0Y_8f6_",
    "outputId": "3e1428f3-a8db-4369-bcc9-b8e6d1bf1e9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlGkRtVa8f9n",
    "outputId": "f0f61ca2-2f20-4e71-d16f-b042899d3123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (dp_one): Dropout(p=0.2, inplace=False)\n",
      "  (dp_two): Dropout(p=0.2, inplace=False)\n",
      "  (bn_one): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_one): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_two): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_two): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_three): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv_three): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn_four): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (out): Linear(in_features=256, out_features=100, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.dp_one = nn.Dropout(0.2)\n",
    "        self.dp_two = nn.Dropout(0.2)\n",
    "        \n",
    "        self.bn_one = torch.nn.BatchNorm2d(3) \n",
    "        self.conv_one = torch.nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.bn_two = torch.nn.BatchNorm2d(16) \n",
    "        self.conv_two = torch.nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.bn_three = torch.nn.BatchNorm2d(32)\n",
    "        self.conv_three = torch.nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.bn_four = torch.nn.BatchNorm2d(64)\n",
    "        self.fc1 = torch.nn.Linear(1024, 512)\n",
    "        self.fc2 = torch.nn.Linear(512, 256)\n",
    "        self.out = torch.nn.Linear(256, 100)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.bn_one(x)\n",
    "        x = self.conv_one(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_two(x)\n",
    "        x = self.conv_two(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_three(x)\n",
    "        x = self.conv_three(x)\n",
    "        x = F.leaky_relu(x, 0.1)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        \n",
    "        x = self.bn_four(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dp_one(x)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dp_two(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        return self.out(x)\n",
    "       \n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tQQLH_XJ8gAX"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p8aIv9lr8gC_",
    "outputId": "26642b72-b1ac-4fd6-ee64-5e7042c921a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm2d-1            [-1, 3, 32, 32]               6\n",
      "            Conv2d-2           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-3           [-1, 16, 16, 16]              32\n",
      "            Conv2d-4           [-1, 32, 16, 16]           4,640\n",
      "       BatchNorm2d-5             [-1, 32, 8, 8]              64\n",
      "            Conv2d-6             [-1, 64, 8, 8]          18,496\n",
      "       BatchNorm2d-7             [-1, 64, 4, 4]             128\n",
      "           Dropout-8                 [-1, 1024]               0\n",
      "            Linear-9                  [-1, 512]         524,800\n",
      "          Dropout-10                  [-1, 512]               0\n",
      "           Linear-11                  [-1, 256]         131,328\n",
      "           Linear-12                  [-1, 100]          25,700\n",
      "================================================================\n",
      "Total params: 705,642\n",
      "Trainable params: 705,642\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.32\n",
      "Params size (MB): 2.69\n",
      "Estimated Total Size (MB): 3.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hU4KHslA8gFg",
    "outputId": "e1291a14-e96f-45f9-e056-7e4c9fb10c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [1/313]. Loss: 0.036. Acc: 0.008. Test acc: 0.012\n",
      "Epoch [1/5]. Step [301/313]. Loss: 0.032. Acc: 0.073. Test acc: 0.081\n",
      "Epoch [2/5]. Step [1/313]. Loss: 0.030. Acc: 0.141. Test acc: 0.091\n",
      "Epoch [2/5]. Step [301/313]. Loss: 0.029. Acc: 0.119. Test acc: 0.106\n",
      "Epoch [3/5]. Step [1/313]. Loss: 0.029. Acc: 0.156. Test acc: 0.105\n",
      "Epoch [3/5]. Step [301/313]. Loss: 0.028. Acc: 0.154. Test acc: 0.159\n",
      "Epoch [4/5]. Step [1/313]. Loss: 0.026. Acc: 0.164. Test acc: 0.124\n",
      "Epoch [4/5]. Step [301/313]. Loss: 0.026. Acc: 0.182. Test acc: 0.146\n",
      "Epoch [5/5]. Step [1/313]. Loss: 0.025. Acc: 0.180. Test acc: 0.155\n",
      "Epoch [5/5]. Step [301/313]. Loss: 0.026. Acc: 0.196. Test acc: 0.164\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "net.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            net.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = net(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "        \n",
    "        net.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b73d58ffac6f497faa653db205aee47c",
      "49ebf02c81dd4a60bbbe66557fa1f4ba",
      "ce3ee39ce0fa4e008a99f25b1723def8",
      "8c5578f912a8471a924e9de56ec1f055",
      "d17be54b2dc04b8994c8d6b50a0812e9",
      "1b1c8ac1805042ed9242c482443672df",
      "bda0e6f271ba4d34a91d06455a131dea",
      "2649a1c1758d44db8e0eef48c3d1bb2a",
      "aa6808e0f7bc4439a555f250cb93dde9",
      "664797180355401181f4870feb9d7bb6",
      "2e87a81ab5e244d1b41ed1a9c603e3e9"
     ]
    },
    "id": "_y_vzsNH8gIP",
    "outputId": "c2ef0f9e-462f-4a00-895f-f171340a78a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
      "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73d58ffac6f497faa653db205aee47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "093klqpR8rgD",
    "outputId": "b4934de3-4deb-4faa-c84e-33c90dce8176"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.87\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 103.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(resnet50.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aSykgv_x8rnQ"
   },
   "outputs": [],
   "source": [
    "for param in list(resnet50.parameters())[:]:\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_shVY0Le8rsP",
    "outputId": "08f0f4fa-31b2-4c07-c6dd-2e3335d836a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 16, 16]           9,408\n",
      "       BatchNorm2d-2           [-1, 64, 16, 16]             128\n",
      "              ReLU-3           [-1, 64, 16, 16]               0\n",
      "         MaxPool2d-4             [-1, 64, 8, 8]               0\n",
      "            Conv2d-5             [-1, 64, 8, 8]           4,096\n",
      "       BatchNorm2d-6             [-1, 64, 8, 8]             128\n",
      "              ReLU-7             [-1, 64, 8, 8]               0\n",
      "            Conv2d-8             [-1, 64, 8, 8]          36,864\n",
      "       BatchNorm2d-9             [-1, 64, 8, 8]             128\n",
      "             ReLU-10             [-1, 64, 8, 8]               0\n",
      "           Conv2d-11            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-12            [-1, 256, 8, 8]             512\n",
      "           Conv2d-13            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-14            [-1, 256, 8, 8]             512\n",
      "             ReLU-15            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-16            [-1, 256, 8, 8]               0\n",
      "           Conv2d-17             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-18             [-1, 64, 8, 8]             128\n",
      "             ReLU-19             [-1, 64, 8, 8]               0\n",
      "           Conv2d-20             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
      "             ReLU-22             [-1, 64, 8, 8]               0\n",
      "           Conv2d-23            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-24            [-1, 256, 8, 8]             512\n",
      "             ReLU-25            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-26            [-1, 256, 8, 8]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          16,384\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "             ReLU-29             [-1, 64, 8, 8]               0\n",
      "           Conv2d-30             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
      "             ReLU-32             [-1, 64, 8, 8]               0\n",
      "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
      "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
      "             ReLU-35            [-1, 256, 8, 8]               0\n",
      "       Bottleneck-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 128, 8, 8]          32,768\n",
      "      BatchNorm2d-38            [-1, 128, 8, 8]             256\n",
      "             ReLU-39            [-1, 128, 8, 8]               0\n",
      "           Conv2d-40            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-41            [-1, 128, 4, 4]             256\n",
      "             ReLU-42            [-1, 128, 4, 4]               0\n",
      "           Conv2d-43            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-44            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-45            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-46            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-47            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-48            [-1, 512, 4, 4]               0\n",
      "           Conv2d-49            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-50            [-1, 128, 4, 4]             256\n",
      "             ReLU-51            [-1, 128, 4, 4]               0\n",
      "           Conv2d-52            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-53            [-1, 128, 4, 4]             256\n",
      "             ReLU-54            [-1, 128, 4, 4]               0\n",
      "           Conv2d-55            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-57            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
      "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
      "             ReLU-61            [-1, 128, 4, 4]               0\n",
      "           Conv2d-62            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-63            [-1, 128, 4, 4]             256\n",
      "             ReLU-64            [-1, 128, 4, 4]               0\n",
      "           Conv2d-65            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-66            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-67            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-68            [-1, 512, 4, 4]               0\n",
      "           Conv2d-69            [-1, 128, 4, 4]          65,536\n",
      "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
      "             ReLU-71            [-1, 128, 4, 4]               0\n",
      "           Conv2d-72            [-1, 128, 4, 4]         147,456\n",
      "      BatchNorm2d-73            [-1, 128, 4, 4]             256\n",
      "             ReLU-74            [-1, 128, 4, 4]               0\n",
      "           Conv2d-75            [-1, 512, 4, 4]          65,536\n",
      "      BatchNorm2d-76            [-1, 512, 4, 4]           1,024\n",
      "             ReLU-77            [-1, 512, 4, 4]               0\n",
      "       Bottleneck-78            [-1, 512, 4, 4]               0\n",
      "           Conv2d-79            [-1, 256, 4, 4]         131,072\n",
      "      BatchNorm2d-80            [-1, 256, 4, 4]             512\n",
      "             ReLU-81            [-1, 256, 4, 4]               0\n",
      "           Conv2d-82            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-83            [-1, 256, 2, 2]             512\n",
      "             ReLU-84            [-1, 256, 2, 2]               0\n",
      "           Conv2d-85           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-86           [-1, 1024, 2, 2]           2,048\n",
      "           Conv2d-87           [-1, 1024, 2, 2]         524,288\n",
      "      BatchNorm2d-88           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-89           [-1, 1024, 2, 2]               0\n",
      "       Bottleneck-90           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-91            [-1, 256, 2, 2]         262,144\n",
      "      BatchNorm2d-92            [-1, 256, 2, 2]             512\n",
      "             ReLU-93            [-1, 256, 2, 2]               0\n",
      "           Conv2d-94            [-1, 256, 2, 2]         589,824\n",
      "      BatchNorm2d-95            [-1, 256, 2, 2]             512\n",
      "             ReLU-96            [-1, 256, 2, 2]               0\n",
      "           Conv2d-97           [-1, 1024, 2, 2]         262,144\n",
      "      BatchNorm2d-98           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-99           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-100           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-101            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-102            [-1, 256, 2, 2]             512\n",
      "            ReLU-103            [-1, 256, 2, 2]               0\n",
      "          Conv2d-104            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-105            [-1, 256, 2, 2]             512\n",
      "            ReLU-106            [-1, 256, 2, 2]               0\n",
      "          Conv2d-107           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-108           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-109           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-110           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-111            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-112            [-1, 256, 2, 2]             512\n",
      "            ReLU-113            [-1, 256, 2, 2]               0\n",
      "          Conv2d-114            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-115            [-1, 256, 2, 2]             512\n",
      "            ReLU-116            [-1, 256, 2, 2]               0\n",
      "          Conv2d-117           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-118           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-119           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-120           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-121            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-122            [-1, 256, 2, 2]             512\n",
      "            ReLU-123            [-1, 256, 2, 2]               0\n",
      "          Conv2d-124            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-125            [-1, 256, 2, 2]             512\n",
      "            ReLU-126            [-1, 256, 2, 2]               0\n",
      "          Conv2d-127           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-128           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-129           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-130           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-131            [-1, 256, 2, 2]         262,144\n",
      "     BatchNorm2d-132            [-1, 256, 2, 2]             512\n",
      "            ReLU-133            [-1, 256, 2, 2]               0\n",
      "          Conv2d-134            [-1, 256, 2, 2]         589,824\n",
      "     BatchNorm2d-135            [-1, 256, 2, 2]             512\n",
      "            ReLU-136            [-1, 256, 2, 2]               0\n",
      "          Conv2d-137           [-1, 1024, 2, 2]         262,144\n",
      "     BatchNorm2d-138           [-1, 1024, 2, 2]           2,048\n",
      "            ReLU-139           [-1, 1024, 2, 2]               0\n",
      "      Bottleneck-140           [-1, 1024, 2, 2]               0\n",
      "          Conv2d-141            [-1, 512, 2, 2]         524,288\n",
      "     BatchNorm2d-142            [-1, 512, 2, 2]           1,024\n",
      "            ReLU-143            [-1, 512, 2, 2]               0\n",
      "          Conv2d-144            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-146            [-1, 512, 1, 1]               0\n",
      "          Conv2d-147           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 1, 1]           4,096\n",
      "          Conv2d-149           [-1, 2048, 1, 1]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-151           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-152           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-153            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-155            [-1, 512, 1, 1]               0\n",
      "          Conv2d-156            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-158            [-1, 512, 1, 1]               0\n",
      "          Conv2d-159           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-161           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-162           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-163            [-1, 512, 1, 1]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-165            [-1, 512, 1, 1]               0\n",
      "          Conv2d-166            [-1, 512, 1, 1]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 1, 1]           1,024\n",
      "            ReLU-168            [-1, 512, 1, 1]               0\n",
      "          Conv2d-169           [-1, 2048, 1, 1]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 1, 1]           4,096\n",
      "            ReLU-171           [-1, 2048, 1, 1]               0\n",
      "      Bottleneck-172           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                  [-1, 100]         204,900\n",
      "================================================================\n",
      "Total params: 23,712,932\n",
      "Trainable params: 204,900\n",
      "Non-trainable params: 23,508,032\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.86\n",
      "Params size (MB): 90.46\n",
      "Estimated Total Size (MB): 96.33\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet50.fc = nn.Linear(2048, 100)\n",
    "\n",
    "summary(resnet50.to(device), input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Be5pvOaL8ru3"
   },
   "outputs": [],
   "source": [
    "\n",
    "resnet50 = resnet50.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Jiyc1ZAx8rxg"
   },
   "outputs": [],
   "source": [
    "train_actions = transforms.Compose([\n",
    "                                   transforms.Resize(256),\n",
    "                                   transforms.RandomCrop(224, padding=4), \n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225]),\n",
    "                                    ])\n",
    "valid_transforms = transforms.Compose([\n",
    "                                      transforms.Resize(224),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                            std=[0.229, 0.224, 0.225]),\n",
    "                                       ])\n",
    "\n",
    "\n",
    "train_dataset, valid_dataset = train_valid_split(dataset)\n",
    "\n",
    "train_dataset = MyOwnCifar(train_dataset, train_actions)\n",
    "valid_dataset = MyOwnCifar(valid_dataset, valid_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "eK4el7Ko8r0B"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=2)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=128,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "eIFxPKS18r4r"
   },
   "outputs": [],
   "source": [
    "params_to_update = []\n",
    "for name, param in resnet50.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(params_to_update, lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1pnjtXTq83Uy",
    "outputId": "2ec3b9e1-35dc-4c37-e6e1-0646380f5688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5]. Step [1/313]. Loss: 0.036. Acc: 0.016. Test acc: 0.014\n",
      "Epoch [1/5]. Step [301/313]. Loss: 0.020. Acc: 0.399. Test acc: 0.483\n",
      "Epoch [2/5]. Step [1/313]. Loss: 0.021. Acc: 0.453. Test acc: 0.474\n",
      "Epoch [2/5]. Step [301/313]. Loss: 0.016. Acc: 0.501. Test acc: 0.501\n",
      "Epoch [3/5]. Step [1/313]. Loss: 0.014. Acc: 0.602. Test acc: 0.493\n",
      "Epoch [3/5]. Step [301/313]. Loss: 0.016. Acc: 0.520. Test acc: 0.525\n",
      "Epoch [4/5]. Step [1/313]. Loss: 0.018. Acc: 0.492. Test acc: 0.523\n",
      "Epoch [4/5]. Step [301/313]. Loss: 0.016. Acc: 0.533. Test acc: 0.520\n",
      "Epoch [5/5]. Step [1/313]. Loss: 0.011. Acc: 0.609. Test acc: 0.531\n",
      "Epoch [5/5]. Step [301/313]. Loss: 0.016. Acc: 0.539. Test acc: 0.529\n",
      "Training is finished!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "resnet50.train()\n",
    "\n",
    "for epoch in range(num_epochs):  \n",
    "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # обнуляем градиент\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = resnet50(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # выводим статистику о процессе обучения\n",
    "        running_loss += loss.item()\n",
    "        running_items += len(labels)\n",
    "        running_right += (labels == torch.max(outputs, 1)[1]).sum()\n",
    "        \n",
    "        # выводим статистику о процессе обучения\n",
    "        if i % 300 == 0:    # печатаем каждые 300 mini-batches\n",
    "            resnet50.eval()\n",
    "            \n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}]. ' \\\n",
    "                  f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
    "                  f'Loss: {running_loss / running_items:.3f}. ' \\\n",
    "                  f'Acc: {running_right / running_items:.3f}', end='. ')\n",
    "            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
    "\n",
    "            test_running_right, test_running_total = 0.0, 0.0\n",
    "            for i, data in enumerate(valid_loader):\n",
    "            \n",
    "                test_outputs = resnet50(data[0].to(device))\n",
    "                test_running_total += len(data[1])\n",
    "                test_running_right += (data[1].to(device) == torch.max(test_outputs, 1)[1]).sum()\n",
    "            \n",
    "            print(f'Test acc: {test_running_right / test_running_total:.3f}')\n",
    "\n",
    "        resnet50.train()\n",
    "        \n",
    "print('Training is finished!')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Homework_4.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1b1c8ac1805042ed9242c482443672df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2649a1c1758d44db8e0eef48c3d1bb2a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e87a81ab5e244d1b41ed1a9c603e3e9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "49ebf02c81dd4a60bbbe66557fa1f4ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b1c8ac1805042ed9242c482443672df",
      "placeholder": "​",
      "style": "IPY_MODEL_bda0e6f271ba4d34a91d06455a131dea",
      "value": "100%"
     }
    },
    "664797180355401181f4870feb9d7bb6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8c5578f912a8471a924e9de56ec1f055": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_664797180355401181f4870feb9d7bb6",
      "placeholder": "​",
      "style": "IPY_MODEL_2e87a81ab5e244d1b41ed1a9c603e3e9",
      "value": " 97.8M/97.8M [00:00&lt;00:00, 248MB/s]"
     }
    },
    "aa6808e0f7bc4439a555f250cb93dde9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b73d58ffac6f497faa653db205aee47c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_49ebf02c81dd4a60bbbe66557fa1f4ba",
       "IPY_MODEL_ce3ee39ce0fa4e008a99f25b1723def8",
       "IPY_MODEL_8c5578f912a8471a924e9de56ec1f055"
      ],
      "layout": "IPY_MODEL_d17be54b2dc04b8994c8d6b50a0812e9"
     }
    },
    "bda0e6f271ba4d34a91d06455a131dea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ce3ee39ce0fa4e008a99f25b1723def8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2649a1c1758d44db8e0eef48c3d1bb2a",
      "max": 102530333,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_aa6808e0f7bc4439a555f250cb93dde9",
      "value": 102530333
     }
    },
    "d17be54b2dc04b8994c8d6b50a0812e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
